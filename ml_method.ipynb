{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "017e9265",
   "metadata": {},
   "source": [
    "# 제품 이상여부 판별 프로젝트\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab431",
   "metadata": {},
   "source": [
    "## 1. 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8341e8",
   "metadata": {},
   "source": [
    "### 필수 라이브러리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a315cc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "from pprint import pprint\n",
    "from typing import Any, Dict\n",
    "\n",
    "import rtdl\n",
    "import scipy.special\n",
    "import zero\n",
    "from collections import Counter\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d054e30",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc0b4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"Data\"\n",
    "RANDOM_STATE = 881\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv(os.path.join(ROOT_DIR, \"train.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118ae22",
   "metadata": {},
   "source": [
    "### 언더 샘플링\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97966549",
   "metadata": {},
   "source": [
    "데이타 불균형을 해결하기 위해 언더 샘플링을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be3d675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total: Normal: 38156, AbNormal: 2350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "target\n",
       "Normal      38156\n",
       "AbNormal     2350\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal = train_data[train_data[\"target\"] == \"Normal\"]\n",
    "df_abnormal = train_data[train_data[\"target\"] == \"AbNormal\"]\n",
    "\n",
    "num_normal = len(df_normal)\n",
    "num_abnormal = len(df_abnormal)\n",
    "print(f\"  Total: Normal: {num_normal}, AbNormal: {num_abnormal}\")\n",
    "\n",
    "normal_ratio = num_normal/num_abnormal  # 1.0 means 1:1 ratio\n",
    "# normal_ratio = 1.0  # 1.0 means 1:1 ratio\n",
    "df_normal = df_normal.sample(n=int(num_abnormal * normal_ratio), replace=False, random_state=RANDOM_STATE)\n",
    "df_concat = pd.concat([df_normal, df_abnormal], axis=0).reset_index(drop=True)\n",
    "df_concat.value_counts(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebeaabc1",
   "metadata": {},
   "source": [
    "### 데이터 분할\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ecfa9b",
   "metadata": {},
   "source": [
    "## 3. 모델 학습\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caf257b",
   "metadata": {},
   "source": [
    "### 모델 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "859a6bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of splits for K-Fold\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4509af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5ed8",
   "metadata": {},
   "source": [
    "### 모델 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "766d1980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding for categorical features\n",
    "features = []\n",
    "\n",
    "# Preprocess df_concat\n",
    "for col in df_concat.columns:\n",
    "    if df_concat[col].dtype == 'object' and col != 'target' and df_concat[col].nunique() > 1:\n",
    "        le = LabelEncoder()\n",
    "        df_concat[col] = le.fit_transform(df_concat[col])\n",
    "        features.append(col)\n",
    "        \n",
    "for col in df_concat.columns:\n",
    "    if df_concat[col].dtype != 'object':\n",
    "        try:\n",
    "            if df_concat[col].nunique() > 1: \n",
    "                df_concat[col] = df_concat[col].astype(int)\n",
    "                features.append(col)\n",
    "        except ValueError:\n",
    "            try: \n",
    "                if df_concat[col].nunique() > 1:\n",
    "                    df_concat[col] = df_concat[col].astype(float)\n",
    "                    features.append(col)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "\n",
    "features = list(set(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cade8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_concat[features]\n",
    "y = df_concat[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de0431f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언더샘플링 및 오버샘플링을 위한 파이프라인 구성\n",
    "over = SMOTE(random_state=RANDOM_STATE)\n",
    "under = RandomUnderSampler(random_state=RANDOM_STATE)\n",
    "pipeline = Pipeline(steps=[('u', under),('o', over)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e6a811e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Train F1-Score: 0.7741269486012018\n",
      "Average Validation F1-Score: 0.7438263053526959\n",
      "Best Validation F1-Score: 0.7526785714285714\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to store F1-scores for each fold\n",
    "f1_scores_train = []\n",
    "f1_scores_val = []\n",
    "\n",
    "# Initialize variables to store the best model and best F1-score\n",
    "best_model = None\n",
    "best_f1_score = 0\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    df_train, df_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    train_y, val_y = y.iloc[train_index], y.iloc[val_index] \n",
    "    #sampling\n",
    "    train_x_resampled, train_y_resampled = pipeline.fit_resample(df_train, train_y)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(train_x_resampled, train_y_resampled)\n",
    "    \n",
    "    # Predictions and F1-score for training set\n",
    "    train_pred = model.predict(df_train)\n",
    "    train_score = f1_score(train_y, train_pred, pos_label='Normal')\n",
    "    f1_scores_train.append(train_score)\n",
    "    \n",
    "    # Predictions and F1-score for validation set\n",
    "    val_pred = model.predict(df_val)\n",
    "    val_score = f1_score(val_y, val_pred, pos_label='Normal')\n",
    "    f1_scores_val.append(val_score)\n",
    "    \n",
    "    # Check if this model has the best validation F1-score\n",
    "    if val_score > best_f1_score:\n",
    "        best_f1_score = val_score\n",
    "        best_model = model\n",
    "\n",
    "# Calculate and print the average F1-scores\n",
    "print(f\"Average Train F1-Score: {np.mean(f1_scores_train)}\")\n",
    "print(f\"Average Validation F1-Score: {np.mean(f1_scores_val)}\")\n",
    "print(f\"Best Validation F1-Score: {best_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53fb01dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 5844, 'AbNormal': 4282})\n"
     ]
    }
   ],
   "source": [
    "# 요소의 개수 세기\n",
    "counter = Counter(val_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adf8300",
   "metadata": {},
   "source": [
    "## 4. 제출하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b6e17",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda16350",
   "metadata": {},
   "source": [
    "테스트 데이터 불러오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e37a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(ROOT_DIR, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1eb2e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess df_test_x similarly\n",
    "for col in test_data.columns:\n",
    "    if test_data[col].dtype == 'object':\n",
    "        if test_data[col].nunique() > 1:\n",
    "            le = LabelEncoder()\n",
    "            test_data[col] = le.fit_transform(test_data[col])\n",
    "            \n",
    "for col in test_data.columns:\n",
    "    if test_data[col].dtype != 'object':\n",
    "        try:\n",
    "            if test_data[col].nunique() > 1: \n",
    "                test_data[col] = test_data[col].astype(int)\n",
    "                \n",
    "        except ValueError:\n",
    "            try: \n",
    "                if test_data[col].nunique() > 1:\n",
    "                    test_data[col] = test_data[col].astype(float)\n",
    "                   \n",
    "            except:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cc79eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_x = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13f7a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Normal': 10104, 'AbNormal': 7257})\n"
     ]
    }
   ],
   "source": [
    "test_pred = model.predict(df_test_x)\n",
    "\n",
    "# 요소의 개수 세기\n",
    "counter = Counter(test_pred)\n",
    "\n",
    "# 결과 출력\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f18e6a",
   "metadata": {},
   "source": [
    "### 제출 파일 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3128a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 데이터 읽어오기 (df_test는 전처리된 데이터가 저장됨)\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"target\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7867ce",
   "metadata": {},
   "source": [
    "**우측 상단의 제출 버튼을 클릭해 결과를 확인하세요**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hari",
   "language": "python",
   "name": "hrenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
